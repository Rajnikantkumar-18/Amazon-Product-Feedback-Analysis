{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f4b042",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO 1 : Import required libraries\n",
    "# Step 1: Import Required Libraries\n",
    "\n",
    "# Basic data and visualization libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Natural Language Processing\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Vectorization (optional for extended analysis)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('https://gitlab.crio.do/me_notebook/me_jupyter_amazonfeedbackanalysis/-/raw/master/amazon_product_reviews.csv')\n",
    "df.head()\n",
    "\n",
    "# Rename column if needed\n",
    "df.columns = [col.lower().strip() for col in df.columns]\n",
    "if 'reviews' not in df.columns:\n",
    "    df.rename(columns={'reviews.text': 'reviews'}, inplace=True)\n",
    "\n",
    "# Drop missing reviews\n",
    "df.dropna(subset=['reviews'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Text Cleaning Function\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "df[\"cleaned_review\"] = df[\"reviews\"].apply(clean_text)\n",
    "\n",
    "# Review Length\n",
    "df[\"review_length\"] = df[\"cleaned_review\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df[\"review_length\"], bins=40, kde=True)\n",
    "plt.title(\"Distribution of Review Lengths\")\n",
    "plt.xlabel(\"Number of Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Sentiment Analysis (VADER)\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(score):\n",
    "    if score >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif score <= -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "df[\"compound_score\"] = df[\"cleaned_review\"].apply(lambda x: sia.polarity_scores(x)[\"compound\"])\n",
    "df[\"sentiment\"] = df[\"compound_score\"].apply(get_sentiment)\n",
    "\n",
    "sns.countplot(data=df, x=\"sentiment\", order=[\"Positive\", \"Neutral\", \"Negative\"])\n",
    "plt.title(\"Review Rating Distribution\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# WordCloud for All Reviews\n",
    "text_all = \" \".join(df[\"cleaned_review\"].astype(str).tolist())\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "wordcloud = WordCloud(width=1000, height=500, background_color=\"white\", stopwords=stop_words).generate(text_all)\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Commonly Used Words\")\n",
    "plt.show()\n",
    "\n",
    "# TextBlob Sentiment\n",
    "def get_sentiment_textblob(text):\n",
    "    polarity = TextBlob(text).sentiment.polarity\n",
    "    if polarity > 0:\n",
    "        return \"Positive\"\n",
    "    elif polarity < 0:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "df['sentiment'] = df['cleaned_review'].apply(get_sentiment_textblob)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='sentiment', order=['Positive', 'Neutral', 'Negative'])\n",
    "plt.title(\"Sentiment Distribution\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Number of Reviews\")\n",
    "plt.show()\n",
    "\n",
    "# Tokenization for Negative Reviews\n",
    "negative_reviews = df[df[\"sentiment\"] == \"Negative\"].copy()\n",
    "\n",
    "def tokenize(text):\n",
    "    return [word for word in text.split() if word not in stop_words]\n",
    "\n",
    "negative_reviews[\"tokens\"] = negative_reviews[\"cleaned_review\"].apply(tokenize)\n",
    "\n",
    "flat_words = [word for tokens in negative_reviews[\"tokens\"] for word in tokens]\n",
    "\n",
    "top_negative_words = Counter(flat_words).most_common(15)\n",
    "words, counts = zip(*top_negative_words)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(counts), y=list(words))\n",
    "plt.title(\"Top Issues from Negative Reviews\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Words\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
